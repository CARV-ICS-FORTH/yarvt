commit bf61a811f84c0f9285a3a0d38e8c64331cb96531
Author: Nick Kossifidis <mick@ics.forth.gr>
Date:   Sat Jun 22 00:13:17 2024 +0300

    Add eupilot-vec machine, xxvnet_carv nic and a fix plic/emaclite

diff --git a/configs/devices/riscv64-softmmu/default.mak b/configs/devices/riscv64-softmmu/default.mak
index bc69301..e332fb0 100644
--- a/configs/devices/riscv64-softmmu/default.mak
+++ b/configs/devices/riscv64-softmmu/default.mak
@@ -14,3 +14,4 @@ CONFIG_SIFIVE_U=y
 CONFIG_RISCV_VIRT=y
 CONFIG_MICROCHIP_PFSOC=y
 CONFIG_SHAKTI_C=y
+CONFIG_SDV3=y
diff --git a/hw/intc/sifive_plic.c b/hw/intc/sifive_plic.c
index 5522ede..3df50e4 100644
--- a/hw/intc/sifive_plic.c
+++ b/hw/intc/sifive_plic.c
@@ -348,7 +348,11 @@ static void parse_hart_config(SiFivePLICState *plic)
 static void sifive_plic_irq_request(void *opaque, int irq, int level)
 {
     SiFivePLICState *s = opaque;
-
+    /* Don't allow sources/gateways to clear the pending bit,
+     * the pending bit should only be cleared when interrupt is
+     * claimed by the host. */
+    if (level <= 0)
+        return;
     sifive_plic_set_pending(s, irq, level > 0);
     sifive_plic_update(s);
 }
diff --git a/hw/net/Kconfig b/hw/net/Kconfig
index 7fcc0d7..a289ae0 100644
--- a/hw/net/Kconfig
+++ b/hw/net/Kconfig
@@ -120,6 +120,10 @@ config COLDFIRE
 config XILINX_ETHLITE
     bool
 
+config XXVNET_CARV
+    bool
+    select PTIMER
+
 config VIRTIO_NET
     bool
     default y
diff --git a/hw/net/meson.build b/hw/net/meson.build
index f64651c..26bb089 100644
--- a/hw/net/meson.build
+++ b/hw/net/meson.build
@@ -44,6 +44,7 @@ system_ss.add(when: 'CONFIG_ETRAXFS', if_true: files('etraxfs_eth.c'))
 system_ss.add(when: 'CONFIG_COLDFIRE', if_true: files('mcf_fec.c'))
 specific_ss.add(when: 'CONFIG_PSERIES', if_true: files('spapr_llan.c'))
 system_ss.add(when: 'CONFIG_XILINX_ETHLITE', if_true: files('xilinx_ethlite.c'))
+system_ss.add(when: 'CONFIG_XXVNET_CARV', if_true: files('xxvnet_carv.c'))
 
 system_ss.add(when: 'CONFIG_VIRTIO_NET', if_true: files('net_rx_pkt.c'))
 specific_ss.add(when: 'CONFIG_VIRTIO_NET', if_true: files('virtio-net.c'))
diff --git a/hw/net/xilinx_ethlite.c b/hw/net/xilinx_ethlite.c
index 989afaf..a30efb6 100644
--- a/hw/net/xilinx_ethlite.c
+++ b/hw/net/xilinx_ethlite.c
@@ -30,6 +30,7 @@
 #include "hw/irq.h"
 #include "hw/qdev-properties.h"
 #include "net/net.h"
+#include "qemu/log.h"
 
 #define D(x)
 #define R_TX_BUF0     0
@@ -51,6 +52,7 @@
 #define CTRL_I     0x8
 #define CTRL_P     0x2
 #define CTRL_S     0x1
+#define CTRL_RW_MASK (CTRL_I | CTRL_P | CTRL_S)
 
 #define TYPE_XILINX_ETHLITE "xlnx.xps-ethernetlite"
 DECLARE_INSTANCE_CHECKER(struct xlx_ethlite, XILINX_ETHLITE,
@@ -67,8 +69,6 @@ struct xlx_ethlite
 
     uint32_t c_tx_pingpong;
     uint32_t c_rx_pingpong;
-    unsigned int txbuf;
-    unsigned int rxbuf;
 
     uint32_t regs[R_MAX];
 };
@@ -91,11 +91,11 @@ eth_read(void *opaque, hwaddr addr, unsigned int size)
 
     switch (addr)
     {
+        case R_TX_CTRL1:
+        case R_TX_CTRL0:
         case R_TX_GIE0:
         case R_TX_LEN0:
         case R_TX_LEN1:
-        case R_TX_CTRL1:
-        case R_TX_CTRL0:
         case R_RX_CTRL1:
         case R_RX_CTRL0:
             r = s->regs[addr];
@@ -122,34 +122,64 @@ eth_write(void *opaque, hwaddr addr,
     {
         case R_TX_CTRL0:
         case R_TX_CTRL1:
-            if (addr == R_TX_CTRL1)
-                base = 0x800 / 4;
 
             D(qemu_log("%s addr=" HWADDR_FMT_plx " val=%x\n",
-                       __func__, addr * 4, value));
+                       __func__, addr, value));
+
+            if (addr == R_TX_CTRL1) {
+                base = R_TX_BUF1;
+                value &= ~CTRL_I;
+            } else
+                base = R_TX_BUF0;
+
+            value &= CTRL_RW_MASK;
+
+            /* User can only set S/P bits, not clear them */
+            value |= (s->regs[addr] & (CTRL_S | CTRL_P));
+
             if ((value & (CTRL_P | CTRL_S)) == CTRL_S) {
-                qemu_send_packet(qemu_get_queue(s->nic),
-                                 (void *) &s->regs[base],
-                                 s->regs[base + R_TX_LEN0]);
-                D(qemu_log("eth_tx %d\n", s->regs[base + R_TX_LEN0]));
-                if (s->regs[base + R_TX_CTRL0] & CTRL_I)
-                    eth_pulse_irq(s);
+
+                if (!(s->regs[addr] & CTRL_S)) {
+                    qemu_send_packet(qemu_get_queue(s->nic),
+                                     (void *) &s->regs[base],
+                                     s->regs[base + R_TX_LEN0]);
+                    D(qemu_log("eth_tx %d\n", s->regs[base + R_TX_LEN0]));
+                    if (s->regs[R_TX_CTRL0] & CTRL_I)
+                        eth_pulse_irq(s);
+                }
+
             } else if ((value & (CTRL_P | CTRL_S)) == (CTRL_P | CTRL_S)) {
-                memcpy(&s->conf.macaddr.a[0], &s->regs[base], 6);
-                if (s->regs[base + R_TX_CTRL0] & CTRL_I)
-                    eth_pulse_irq(s);
+
+                if (!(s->regs[addr] & CTRL_P)) {
+                    memcpy(&s->conf.macaddr.a[0], &s->regs[base], 6);
+                    D(qemu_log("mac address set\n"));
+                    if (s->regs[R_TX_CTRL0] & CTRL_I)
+                        eth_pulse_irq(s);
+                }
             }
 
-            /* We are fast and get ready pretty much immediately so
-               we actually never flip the S nor P bits to one.  */
-            s->regs[addr] = value & ~(CTRL_P | CTRL_S);
+            /* TX / Programming done, clear S/P bits */
+            value &= ~(CTRL_S | CTRL_P);
+            s->regs[addr] = value;
+
             break;
 
         /* Keep these native.  */
         case R_RX_CTRL0:
         case R_RX_CTRL1:
-            if (!(value & CTRL_S)) {
-                qemu_flush_queued_packets(qemu_get_queue(s->nic));
+            value &= CTRL_RW_MASK;
+            if (addr == R_RX_CTRL1)
+                value &= ~CTRL_I;
+            /* User can only clear S bit, not set it */
+            if (s->regs[addr] & CTRL_S) {
+                if (!(value & CTRL_S)) {
+                    qemu_flush_queued_packets(qemu_get_queue(s->nic));
+                } else {
+                    value |= CTRL_S;
+                    /* Do we need to trigger an interrupt ? */
+                    if ((s->regs[R_RX_CTRL0] & CTRL_I) || value & CTRL_I)
+                        eth_pulse_irq(s);
+                }
             }
             /* fall through */
         case R_TX_LEN0:
@@ -179,47 +209,49 @@ static const MemoryRegionOps eth_ops = {
 static bool eth_can_rx(NetClientState *nc)
 {
     struct xlx_ethlite *s = qemu_get_nic_opaque(nc);
-    unsigned int rxbase = s->rxbuf * (0x800 / 4);
 
-    return !(s->regs[rxbase + R_RX_CTRL0] & CTRL_S);
+    return !((s->regs[R_RX_CTRL0] & CTRL_S) &&
+             (s->c_rx_pingpong && s->regs[R_RX_CTRL1] & CTRL_S));
 }
 
 static ssize_t eth_rx(NetClientState *nc, const uint8_t *buf, size_t size)
 {
     struct xlx_ethlite *s = qemu_get_nic_opaque(nc);
-    unsigned int rxbase = s->rxbuf * (0x800 / 4);
+    D(static int lost_count = 0;)
+
+    if (size > (R_RX_CTRL0 - R_RX_BUF0) * 4) {
+        D(qemu_log("ethlite packet is too big, size=%li\n", size));
+        return 0;
+    }
 
     /* DA filter.  */
     if (!(buf[0] & 0x80) && memcmp(&s->conf.macaddr.a[0], buf, 6))
         return size;
 
-    if (s->regs[rxbase + R_RX_CTRL0] & CTRL_S) {
-        D(qemu_log("ethlite lost packet %x\n", s->regs[R_RX_CTRL0]));
-        return -1;
-    }
-
-    D(qemu_log("%s %zd rxbase=%x\n", __func__, size, rxbase));
-    if (size > (R_MAX - R_RX_BUF0 - rxbase) * 4) {
-        D(qemu_log("ethlite packet is too big, size=%x\n", size));
-        return -1;
+    if (!(s->regs[R_RX_CTRL0] & CTRL_S)) {
+        memcpy(&s->regs[R_RX_BUF0], buf, size);
+        s->regs[R_RX_CTRL0] |= CTRL_S;
+    } else if (s->c_rx_pingpong && !(s->regs[R_RX_CTRL1] & CTRL_S)) {
+        memcpy(&s->regs[R_RX_BUF1], buf, size);
+        s->regs[R_RX_CTRL1] |= CTRL_S;
+    } else {
+        D(lost_count++;)
+        D(qemu_log("%s lost packet, size: %li, count: %i\n",
+                   __func__, size, lost_count));
+        return 0;
     }
-    memcpy(&s->regs[rxbase + R_RX_BUF0], buf, size);
 
-    s->regs[rxbase + R_RX_CTRL0] |= CTRL_S;
+    D(qemu_log("%s got packet, size: %li\n", __func__, size));
     if (s->regs[R_RX_CTRL0] & CTRL_I) {
         eth_pulse_irq(s);
     }
 
-    /* If c_rx_pingpong was set flip buffers.  */
-    s->rxbuf ^= s->c_rx_pingpong;
     return size;
 }
 
 static void xilinx_ethlite_reset(DeviceState *dev)
 {
-    struct xlx_ethlite *s = XILINX_ETHLITE(dev);
-
-    s->rxbuf = 0;
+    return;
 }
 
 static NetClientInfo net_xilinx_ethlite_info = {
diff --git a/hw/net/xxvnet_carv.c b/hw/net/xxvnet_carv.c
new file mode 100644
index 0000000..6fd25e9
--- /dev/null
+++ b/hw/net/xxvnet_carv.c
@@ -0,0 +1,858 @@
+/*
+ * QEMU model of the XXVNET CARV NIC (based on Xilinx AXI DMA).
+ *
+ * Copyright (c) 2024 Nick Kossifidis <mick@ics.forth.gr>
+ *		      CARV ICS/FORTH
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+#include "qemu/osdep.h"
+#include "qemu/log.h"
+#include "sysemu/dma.h"
+#include "hw/sysbus.h"
+#include "hw/irq.h"
+#include "hw/ptimer.h"
+#include "hw/qdev-properties.h"
+#include "net/net.h"
+
+
+#define D(x)
+
+#define TYPE_XXVNET_CARV "xlnx.xxvnet_carv"
+DECLARE_INSTANCE_CHECKER(struct axidma_state, XXVNET_CARV,
+                         TYPE_XXVNET_CARV)
+/**************\
+* REGISTER MAP *
+\**************/
+
+/* Per-Channel registers */
+
+/* DMA Control Register */
+#define	AXIDMA_DMACR	0x00
+
+enum dmacr_fields {
+	DMACR_RS = 1,
+	DMACR_TAILPTR_MODE = 1 << 1,
+	DMACR_RESET = 1 << 2,
+	DMACR_KEYHOLE = 1 << 3,
+	DMACR_CYCLIC_BD = 1 << 4,
+	DMACR_RESERVED = 0x7F << 5,
+	DMACR_INTR_ON_COMPLETE = 1 << 12,
+	DMACR_INTR_ON_DELAY = 1 << 13,
+	DMACR_INTR_ON_ERROR = 1 << 14,
+	DMACR_RESERVED2 = 1 << 15,
+	DMACR_IRQ_THRESH = 0xFF << 16,
+	DMACR_IRQ_DELAY = 0XFF << 24
+};
+
+#define AXIDMA_DMACR_RW_MASK ~(DMACR_TAILPTR_MODE | \
+			       DMACR_KEYHOLE | \
+			       DMACR_RESERVED | \
+			       DMACR_RESERVED2);
+
+/* DMA Status Register */
+#define AXIDMA_DMASR	(0x04 / 4)
+
+/* DMA Status Register fields */
+enum dmasr_fields {
+	DMASR_HALTED = 1,
+	DMASR_IDLE = 1 << 1,
+	DMASR_SG_INCLUDED = 1 << 3,
+	DMASR_INTERNAL_ERROR = 1 << 4,
+	DMASR_SLAVE_ERROR = 1 << 5,
+	DMASR_DECODE_ERROR = 1 << 6,
+	DMASR_SG_INTERNAL_ERROR = 1 << 8,
+	DMASR_SG_SLAVE_ERROR = 1 << 9,
+	DMASR_SG_DECODE_ERROR = 1 << 10,
+	DMASR_INTR_ON_COMPLETE = 1 << 12,
+	DMASR_INTR_ON_DELAY = 1 << 13,
+	DMASR_INTR_ON_ERROR = 1 << 14,
+	DMASR_IRQ_THRESH = 0xFF << 16,
+	DMASR_IRQ_DELAY = 0xFF << 24
+};
+
+#define AXIDMA_DMASR_RW_MASK	(DMASR_INTR_ON_COMPLETE | \
+				 DMASR_INTR_ON_DELAY | \
+				 DMASR_INTR_ON_ERROR)
+
+#define AXIDMA_DMASR_ERR_MASK	(DMASR_INTERNAL_ERROR | \
+				 DMASR_SLAVE_ERROR | \
+				 DMASR_DECODE_ERROR | \
+				 DMASR_SG_INTERNAL_ERROR | \
+				 DMASR_SG_SLAVE_ERROR | \
+				 DMASR_SG_DECODE_ERROR)
+
+/* Current Descriptor Pointer (SG only) */
+#define AXIDMA_CURDESC		(0x08 / 4)
+#define AXIDMA_CURDESC_MSB	(0x0C / 4)
+
+/* Tail Descriptor Pointer (SG only) */
+#define AXIDMA_TAILDESC		(0x10 / 4)
+#define AXIDMA_TAILDESC_MSB	(0x14 / 4)
+
+/* Direct transfer buffer address (Direct only) */
+#define	AXIDMA_BUFFER_ADDR	(0x18 / 4)
+#define	AXIDMA_BUFFER_ADDR_MSB	(0x1c / 4)
+
+/* Direct transfer buffer length (bytes) (Direct only) */
+#define	AXIDMA_BUFFER_LENGTH	(0x28 / 4)
+
+/* Scatter/Gather User and Cache (SG / MM2S only) */
+#define AXIDMA_SG_CTL		(0x2C / 4)
+
+#define AXIDMA_CHAN_REG_MAX	(0x30 / 4)
+
+/* Note: same bits on DMASR/DMACR */
+#define AXIDMA_CHAN_INTR_MASK	(DMASR_INTR_ON_COMPLETE | \
+				 DMASR_INTR_ON_DELAY | \
+				 DMASR_INTR_ON_ERROR)
+
+#define XXVNET_MM2S_BASE	0x00
+#define XXVNET_S2MM_BASE	AXIDMA_CHAN_REG_MAX * 4
+
+#define MAX_PACKET_SIZE		4096
+
+/*******************\
+* DESCRIPTOR FORMAT *
+\*******************/
+
+#define APP_SPECIFIC_REGISTERS_NUM	5
+
+struct axidma_desc {
+	uint64_t next;
+	uint64_t buffer_addr;
+	uint64_t reserved;
+	uint32_t control;
+	uint32_t status;
+	uint32_t app[APP_SPECIFIC_REGISTERS_NUM];
+};
+
+enum desc_control_fields {
+	STR_CTL_LEN_MASK = (1 << 26) - 1,
+	STR_CTL_TXEOF = (1 << 26),
+	STR_CTL_TXSOF = (1 << 27),
+};
+
+enum desc_status_fields {
+	STR_STS_LEN_MASK = (1 << 26) - 1,
+	STR_STS_RXEOF = (1 << 26),
+	STR_STS_RXSOF = (1 << 27),
+	STR_STS_INTERNAL_ERROR = (1 << 28),
+	STR_STS_SLAVE_ERROR = (1 << 29),
+	STR_STS_DECODE_ERROR = (1 << 20),
+	STR_STS_COMPLETED = (1 << 31)
+};
+
+/***************\
+* CHANNEL STATE *
+\***************/
+
+struct axidma_channel {
+	uint32_t regs[AXIDMA_CHAN_REG_MAX];
+
+	int id;
+	qemu_irq irq;
+
+	/* For interrupt coalescing */
+	ptimer_state *delay_timer;
+	int ioc_counter;
+
+	/* Copy of current descriptor */
+	struct axidma_desc cur_desc_copy;
+
+	/* Stream buffer */
+	uint8_t	stream_buff[MAX_PACKET_SIZE];
+	uint16_t stream_buff_pos;
+
+	bool paused;
+};
+
+enum axidma_channel_id {
+	CHAN_MM2S = 0,
+	CHAN_S2MM = 1,
+};
+
+/**************\
+* DEVICE STATE *
+\**************/
+
+struct axidma_state {
+	SysBusDevice parent_obj;
+	MemoryRegion iomem;
+	AddressSpace addr_space;
+	uint32_t sg_clk_rate_hz;
+	NICState *nic;
+	NICConf conf;
+	struct axidma_channel mm2s;
+	struct axidma_channel s2mm;
+};
+
+
+/*********\
+* HELPERS *
+\*********/
+
+static inline bool axidma_chan_active(struct axidma_channel *chan)
+{
+	return (chan->regs[AXIDMA_DMACR] & DMACR_RS) ? true : false;
+}
+
+static void axidma_eval_intr_status(struct axidma_channel *chan)
+{
+	uint32_t pending = chan->regs[AXIDMA_DMASR] & AXIDMA_CHAN_INTR_MASK;
+	uint32_t enabled = chan->regs[AXIDMA_DMACR] & AXIDMA_CHAN_INTR_MASK;
+	if (pending & enabled) {
+		D(qemu_log("%s: got intr on chan %i, mask: 0x%x\n",__func__,
+			   chan->id, pending));
+		qemu_set_irq(chan->irq, true);
+	} else
+		qemu_set_irq(chan->irq, false);
+}
+
+static void axidma_dtimer_reset(struct axidma_channel *chan, bool run)
+{
+	uint8_t dmacr_irq_delay_field = ((chan->regs[AXIDMA_DMACR] >> 24) & 0xFF);
+	/* DMACR IRQ Delay field is in increments of 125 * sg clock period */
+	if (dmacr_irq_delay_field) {
+		ptimer_transaction_begin(chan->delay_timer);
+		ptimer_stop(chan->delay_timer);
+		ptimer_set_count(chan->delay_timer, dmacr_irq_delay_field * 125);
+		if (run)
+			ptimer_run(chan->delay_timer, 1);
+		ptimer_transaction_commit(chan->delay_timer);
+	}
+}
+
+static void axidma_trigger_error(struct axidma_channel *chan, uint32_t dmasr)
+{
+	D(qemu_log("%s: error on channel %i, dmasr: 0x%x\n",__func__, chan->id, dmasr));
+	chan->regs[AXIDMA_DMASR] |= dmasr | DMASR_HALTED | DMASR_INTR_ON_ERROR;
+	chan->regs[AXIDMA_DMACR] &= ~(DMACR_RS);
+	axidma_eval_intr_status(chan);
+}
+
+static void axidma_dtimer_trigger(void *arg)
+{
+	struct axidma_channel *chan = (struct axidma_channel *) arg;
+	if (chan->regs[AXIDMA_DMACR] & DMACR_RS) {
+		chan->regs[AXIDMA_DMASR] |= DMASR_INTR_ON_DELAY;
+		axidma_eval_intr_status(chan);
+	}
+}
+
+static void axidma_dtimer_init(struct axidma_state *state, struct axidma_channel *chan)
+{
+	chan->delay_timer = ptimer_init(axidma_dtimer_trigger, chan, PTIMER_POLICY_LEGACY);
+	ptimer_transaction_begin(chan->delay_timer);
+	ptimer_set_freq(chan->delay_timer, state->sg_clk_rate_hz);
+	ptimer_transaction_commit(chan->delay_timer);
+}
+
+static void axidma_ioc_update(struct axidma_channel *chan)
+{
+	unsigned int irq_thres = (chan->regs[AXIDMA_DMACR] & DMACR_IRQ_THRESH) >> 16;
+	chan->ioc_counter = irq_thres == 0 ? 1 : irq_thres;
+}
+
+static void axidma_transfer_complete(struct axidma_channel *chan)
+{
+	axidma_dtimer_reset(chan, true);
+
+	if (chan->ioc_counter > 0)
+		chan->ioc_counter--;
+
+	if (chan->ioc_counter == 0) {
+		chan->regs[AXIDMA_DMASR] |= DMASR_INTR_ON_COMPLETE;
+		chan->ioc_counter = ((chan->regs[AXIDMA_DMACR] >> 16) & 0xFF);
+		axidma_eval_intr_status(chan);
+	}
+
+	chan->stream_buff_pos = 0;
+}
+
+static void axidma_chan_reset(struct axidma_channel *chan)
+{
+	axidma_dtimer_reset(chan, false);
+	/* TAILPTR_MODE is alwasy 1, IRQ thres minimum is 1 */
+	chan->regs[AXIDMA_DMACR] = DMACR_TAILPTR_MODE | (1 << 16);
+	/* Start in halted state, no errors/intrs, and SG_INCLUDED hardcoded to 1 */
+	chan->regs[AXIDMA_DMASR] = DMASR_HALTED | DMASR_SG_INCLUDED;
+	chan->stream_buff_pos = 0;
+}
+
+static void axidma_reset(struct axidma_state *state)
+{
+	D(qemu_log("%s triggered\n", __func__));
+	axidma_chan_reset(&state->mm2s);
+	axidma_chan_reset(&state->s2mm);
+}
+
+static void axidma_init_state(struct axidma_state *state)
+{
+	axidma_reset(state);
+	state->mm2s.id = CHAN_MM2S;
+	state->s2mm.id = CHAN_S2MM;
+}
+
+static MemTxResult axidma_load_current_desc(struct axidma_state *state, struct axidma_channel *chan)
+{
+	struct axidma_desc *desc = &chan->cur_desc_copy;
+	hwaddr curdesc_ptr = le64_to_cpu(*((hwaddr *) (&chan->regs[AXIDMA_CURDESC])));
+
+	MemTxResult ret = address_space_read(&state->addr_space, curdesc_ptr,
+					     MEMTXATTRS_UNSPECIFIED, desc,
+					     sizeof (struct axidma_desc));
+	if (ret != MEMTX_OK)
+		return ret;
+
+	desc->next = le64_to_cpu(desc->next);
+	desc->buffer_addr = le64_to_cpu(desc->buffer_addr);
+	desc->control = le32_to_cpu(desc->control);
+	desc->status = le32_to_cpu(desc->status);
+
+	return MEMTX_OK;
+}
+
+static MemTxResult axidma_store_current_desc(struct axidma_state *state, struct axidma_channel *chan)
+{
+	struct axidma_desc *desc = &chan->cur_desc_copy;
+	hwaddr curdesc_ptr = le64_to_cpu(*((hwaddr *) (&chan->regs[AXIDMA_CURDESC])));
+	MemTxResult ret = MEMTX_OK;
+
+	desc->next = cpu_to_le64(desc->next);
+	desc->buffer_addr = cpu_to_le64(desc->buffer_addr);
+	desc->reserved = 0;
+	desc->control = cpu_to_le32(desc->control);
+	desc->status = cpu_to_le32(desc->status);
+
+	ret = address_space_write(&state->addr_space, curdesc_ptr,
+				  MEMTXATTRS_UNSPECIFIED, desc,
+				  sizeof (struct axidma_desc));
+	return ret;
+}
+
+/**********************\
+* TRANSMIT PATH (MM2S) *
+\**********************/
+
+static void axidma_mm2s_process(struct axidma_state *state)
+{
+	struct axidma_channel *chan = &state->mm2s;
+	bool eof = false;
+
+	D(qemu_log("%s tx engine start\n", __func__));
+
+	/* User may send us packets in fragments, or move tail descriptor
+	 * while processing, hence the loop. */
+	while(true) {
+		/* Load current descriptor */
+		MemTxResult ret = axidma_load_current_desc(state, chan);
+		if (ret != MEMTX_OK) {
+			if (ret == MEMTX_DECODE_ERROR)
+				axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+			else
+				axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+			break;
+		}
+
+		struct axidma_desc *desc = &chan->cur_desc_copy;
+		/* If we resume operation from IDLE, it means we've already processed
+		 * the current descriptor (which was our previous tail descriptor), clear
+		 * the IDLE bit and resume operation from the next descriptor. */
+		if (chan->regs[AXIDMA_DMASR] & DMASR_IDLE) {
+			chan->regs[AXIDMA_DMASR] &= ~DMASR_IDLE;
+			*((uint64_t*) &chan->regs[AXIDMA_CURDESC]) = cpu_to_le64(desc->next);
+			continue;
+		}
+
+		/* Reached a descriptor marked as completed, the other end
+		 * hasn't processed this descriptor yet, halt and wait for
+		 * the other end to catch up with us and resert. Ignore this
+		 * if cyclic BD mode is enabled. */
+		if (desc->status & STR_STS_COMPLETED &&
+		    !(chan->regs[AXIDMA_DMACR] & DMACR_CYCLIC_BD)) {
+			axidma_trigger_error(chan, DMASR_SG_INTERNAL_ERROR);
+			break;
+		}
+
+		/* Start of a new packet, seek to the begining of the buffer
+		 * (possibly throwing away any unfinished packet), reset
+		 * (and stop) delay timer, it'll start again on EOF. */
+		if (desc->control & STR_CTL_TXSOF) {
+			chan->stream_buff_pos = 0;
+			axidma_dtimer_reset(chan, false);
+			D(qemu_log("%s got sof\n", __func__));
+		}
+
+		/* Verify the length field, trigger internal error if zero,
+		 * and make sure we won't overflow the stream buffer. */
+		int buff_len = (desc->control & STR_CTL_LEN_MASK);
+		if (buff_len == 0) {
+			axidma_trigger_error(chan, DMASR_INTERNAL_ERROR);
+			desc->status |= STR_STS_INTERNAL_ERROR;
+			ret = axidma_store_current_desc(state, chan);
+			if (ret != MEMTX_OK) {
+				if (ret == MEMTX_DECODE_ERROR)
+					axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+				else
+					axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+			}
+			break;
+		}
+
+		if ((chan->stream_buff_pos + buff_len) > MAX_PACKET_SIZE) {
+			D(qemu_log("%s fragment len truncated: %i\n", __func__, buff_len));
+			buff_len = MAX_PACKET_SIZE - chan->stream_buff_pos;
+		}
+
+		/* Fill stream buffer */
+		if (buff_len > 0) {
+			hwaddr src = desc->buffer_addr;
+			uint8_t *dst = (chan->stream_buff + chan->stream_buff_pos);
+			D(qemu_log("%s got fragment, len: %i, addr: 0x" HWADDR_FMT_plx "\n",
+				   __func__, buff_len, src));
+			ret = address_space_read(&state->addr_space, src,
+						MEMTXATTRS_UNSPECIFIED,
+						dst, buff_len);
+			if (ret != MEMTX_OK) {
+				D(qemu_log("%s buffer read failed, addr: 0x" HWADDR_FMT_plx " ret: %i\n",
+					   __func__, src, ret));
+				if (ret == MEMTX_DECODE_ERROR) {
+					axidma_trigger_error(chan, DMASR_SG_DECODE_ERROR);
+					desc->status |= STR_STS_DECODE_ERROR;
+				} else {
+					axidma_trigger_error(chan, DMASR_SG_SLAVE_ERROR);
+					desc->status |= STR_STS_SLAVE_ERROR;
+				}
+				ret = axidma_store_current_desc(state, chan);
+				if (ret != MEMTX_OK) {
+					if (ret == MEMTX_DECODE_ERROR)
+						axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+					else
+						axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+				}
+				break;
+			}
+			chan->stream_buff_pos += buff_len;
+		}
+
+		/* Last fragment for this packet */
+		eof = (desc->control & STR_CTL_TXEOF);
+
+		/* Mark descriptor as completed, releasing it so that it can
+		 * be used by the other end. */
+		desc->status = buff_len | STR_STS_COMPLETED;
+		ret = axidma_store_current_desc(state, chan);
+		if (ret != MEMTX_OK) {
+			if (ret == MEMTX_DECODE_ERROR)
+				axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+			else
+				axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+			break;
+		}
+
+		/* Got a full packet, signal a completed transfer and route
+		 * packet through qemu */
+		if (eof) {
+			qemu_send_packet(qemu_get_queue(state->nic),
+					 (void *) chan->stream_buff,
+					 chan->stream_buff_pos);
+			D(qemu_log("%s packet sent: %i\n", __func__, chan->stream_buff_pos));
+			axidma_transfer_complete(chan);
+		}
+
+		/* Check if we reached the tail descriptor */
+		hwaddr curdesc_ptr = *((hwaddr *) (&chan->regs[AXIDMA_CURDESC]));
+		hwaddr taildesc_ptr = *((hwaddr *) (&chan->regs[AXIDMA_TAILDESC]));
+
+		if (curdesc_ptr == taildesc_ptr) {
+			chan->regs[AXIDMA_DMASR] |= DMASR_IDLE;
+			break;
+		}
+
+		/* Move on to the next descriptor */
+		/* Note: axidma_store_current_desc has already converted this to le64 */
+		*((uint64_t*) &chan->regs[AXIDMA_CURDESC]) = desc->next;
+	}
+	D(qemu_log("%s tx engine stop\n", __func__));
+}
+
+/*********************\
+* RECEIVE PATH (S2MM) *
+\*********************/
+
+static void axidma_s2mm_process(struct axidma_state *state, const uint8_t *inbuff, size_t inbuff_len)
+{
+	struct axidma_channel *chan = &state->s2mm;
+
+	if (!axidma_chan_active(chan))
+		return;
+
+	if (inbuff_len == 0)
+		return;
+
+	D(qemu_log("%s rx start: %li\n", __func__, inbuff_len));
+
+	/* Load current descriptor */
+ resume:
+	MemTxResult ret = axidma_load_current_desc(state, chan);
+	if (ret != MEMTX_OK) {
+		if (ret == MEMTX_DECODE_ERROR)
+			axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+		else
+			axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+		return;
+	}
+
+	struct axidma_desc *desc = &chan->cur_desc_copy;
+	/* If we resume operation from IDLE, it means we've already processed
+	 * the current descriptor (which was our previous tail descriptor), clear
+	 * the IDLE bit and resume operation from the next descriptor. */
+	if (chan->regs[AXIDMA_DMASR] & DMASR_IDLE) {
+		chan->regs[AXIDMA_DMASR] &= ~DMASR_IDLE;
+		*((uint64_t*) &chan->regs[AXIDMA_CURDESC]) = cpu_to_le64(desc->next);
+		goto resume;
+	}
+
+	/* Reached a descriptor marked as completed, the other end
+	 * hasn't released this descriptor yet, halt and wait for
+	 * the other end to catch up with us and resert. Ignore this
+	 * if cyclic BD mode is enabled. */
+	if (desc->status & STR_STS_COMPLETED &&
+	    !(chan->regs[AXIDMA_DMACR] & DMACR_CYCLIC_BD)) {
+		axidma_trigger_error(chan, DMASR_SG_INTERNAL_ERROR);
+		D(qemu_log("%s lost packet: %li\n", __func__, inbuff_len));
+		return;
+	}
+
+	/* Verify the length field, trigger internal error if zero,
+	 * and make sure we won't overflow the target buffer. In this case
+	 * the stream buffer is already full and we are about to drain it.*/
+	int buff_len = (desc->control & STR_CTL_LEN_MASK);
+	if (buff_len == 0) {
+		axidma_trigger_error(chan, DMASR_INTERNAL_ERROR);
+		desc->status |= STR_STS_INTERNAL_ERROR;
+		ret = axidma_store_current_desc(state, chan);
+		if (ret != MEMTX_OK) {
+			if (ret == MEMTX_DECODE_ERROR)
+				axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+			else
+				axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+		}
+		return;
+	}
+
+	/* Packet won't fit in target buffer, drop it */
+	if (inbuff_len > buff_len) {
+		D(qemu_log("%s received packet too big: %li > %i \n",
+		  __func__, inbuff_len, buff_len));
+		return;
+	}
+
+	hwaddr dst = desc->buffer_addr;
+	ret = address_space_write(&state->addr_space, dst,
+				MEMTXATTRS_UNSPECIFIED,
+				inbuff, inbuff_len);
+	if (ret != MEMTX_OK) {
+		if (ret == MEMTX_DECODE_ERROR) {
+			axidma_trigger_error(chan, DMASR_SG_DECODE_ERROR);
+			desc->status |= STR_STS_DECODE_ERROR;
+		} else {
+			axidma_trigger_error(chan, DMASR_SG_SLAVE_ERROR);
+			desc->status |= STR_STS_SLAVE_ERROR;
+		}
+		ret = axidma_store_current_desc(state, chan);
+		if (ret != MEMTX_OK) {
+			if (ret == MEMTX_DECODE_ERROR)
+				axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+			else
+				axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+		}
+		return;
+	}
+
+	desc->status = (inbuff_len & STR_STS_LEN_MASK) |
+			STR_STS_COMPLETED |
+			STR_STS_RXSOF |
+			STR_STS_RXEOF;
+
+	ret = axidma_store_current_desc(state, chan);
+	if (ret != MEMTX_OK) {
+		if (ret == MEMTX_DECODE_ERROR)
+			axidma_trigger_error(chan, DMASR_DECODE_ERROR);
+		else
+			axidma_trigger_error(chan, DMASR_SLAVE_ERROR);
+		return;
+	}
+
+	D(qemu_log("%s rx complete: %li\n", __func__, inbuff_len));
+	axidma_transfer_complete(chan);
+
+	/* Check if we reached the tail descriptor */
+	hwaddr curdesc_ptr = *((hwaddr *) (&chan->regs[AXIDMA_CURDESC]));
+	hwaddr taildesc_ptr = *((hwaddr *) (&chan->regs[AXIDMA_TAILDESC]));
+
+	if (curdesc_ptr == taildesc_ptr) {
+		chan->regs[AXIDMA_DMASR] |= DMASR_IDLE;
+		return;
+	}
+
+	/* Move on to the next descriptor */
+	/* Note: axidma_store_current_desc has already converted this to le64 */
+	*((uint64_t*) &chan->regs[AXIDMA_CURDESC]) = desc->next;
+}
+
+static bool xxvnet_can_rx(NetClientState *nc)
+{
+	struct axidma_state *state = qemu_get_nic_opaque(nc);
+	struct axidma_channel *chan = &state->s2mm;
+	return axidma_chan_active(chan);
+}
+
+static ssize_t xxvnet_rx(NetClientState *nc, const uint8_t *buf, size_t size)
+{
+	struct axidma_state *state = qemu_get_nic_opaque(nc);
+	struct axidma_channel *chan = &state->s2mm;
+	axidma_s2mm_process(state, buf, size);
+	/* If an error occured we failed to send the packet and the
+	 * engine has stopped, return 0 to stop rx queue. We'll restart
+	 * rx queue later on when we call qemu_flush_queued_packets(). */
+	if (chan->regs[AXIDMA_DMASR] & DMASR_HALTED)
+		return 0;
+	else
+		return size;
+}
+
+static NetClientInfo net_xxvnet_carv_info = {
+    .type = NET_CLIENT_DRIVER_NIC,
+    .size = sizeof(NICState),
+    .can_receive = xxvnet_can_rx,
+    .receive = xxvnet_rx,
+};
+
+/*************\
+* MMIO ACCESS *
+\*************/
+
+static uint64_t axidma_read(void *opaque, hwaddr addr, unsigned int size)
+{
+	struct axidma_state *state = (struct axidma_state *) opaque;
+	struct axidma_channel *chan = (addr >= XXVNET_S2MM_BASE) ?
+				      &state->s2mm : &state->mm2s;
+	uint64_t val = 0;
+	/* Turn address to an index in regs array */
+	hwaddr reg_offt = addr >> 2;
+	reg_offt %= AXIDMA_CHAN_REG_MAX;
+
+	switch (reg_offt) {
+		case AXIDMA_DMACR:
+			/* run/stop bit set by user, cleared by axidma_trigger_error() */
+			/* reset bit set by user, cleared by axidma_chan_reset() */
+			/* TAILPTR should always be 1, set during init */
+			/* in our case DRE is enabled so keyhole is always 0 */
+			/* cyclic bd maintained by user */
+			/* INTR_ON_* bits maintained by user */
+			/* IRQ_* fields maintained by user */
+			val = chan->regs[reg_offt];
+			break;
+		case AXIDMA_DMASR:
+			/* all fields maintained by engine code above,
+			 * except DMASR_SG_INCLUDED and IRQ_* fields that we'll
+			 * update here. */
+			chan->regs[reg_offt] &= 0xffff;
+			chan->regs[reg_offt] |= (chan->ioc_counter & 0xff) << 16;
+			chan->regs[reg_offt] |= (ptimer_get_count(chan->delay_timer) & 0xff) << 24;
+			val = chan->regs[reg_offt] | DMASR_SG_INCLUDED;;
+			break;
+		/* Unused registers */
+		case AXIDMA_BUFFER_ADDR:
+		case AXIDMA_BUFFER_ADDR_MSB:
+		case AXIDMA_BUFFER_LENGTH:
+		case AXIDMA_SG_CTL:
+			val = 0;
+			break;
+		default:
+			val = chan->regs[reg_offt];
+			break;
+	}
+	D(qemu_log("%s chan %i addr: " HWADDR_FMT_plx " val: %lx\n",
+		   __func__, chan->id, reg_offt * 4, val));
+	return val;
+}
+
+static void axidma_write(void *opaque, hwaddr addr, uint64_t val,
+			 unsigned int size)
+{
+	struct axidma_state *state = (struct axidma_state *) opaque;
+	struct axidma_channel *chan = (addr >= XXVNET_S2MM_BASE) ?
+				      &state->s2mm : &state->mm2s;
+
+	/* Turn address to an index in regs array */
+	hwaddr reg_offt = addr >> 2;
+	reg_offt %= AXIDMA_CHAN_REG_MAX;
+
+	D(qemu_log("%s chan %i addr: " HWADDR_FMT_plx " val: %lx\n",
+		   __func__, chan->id, reg_offt * 4, val));
+
+	switch (reg_offt) {
+		case AXIDMA_DMACR:
+			/* Ignore reserved/unsupported/hardcoded fields */
+			val &= AXIDMA_DMACR_RW_MASK;
+
+			/* cyclic_bd may only be set when channel is inactive */
+			if ((chan->regs[AXIDMA_DMACR] & DMACR_RS) && val & DMACR_CYCLIC_BD)
+				val &= ~DMACR_CYCLIC_BD;
+
+			/* User can only set reset bit, not clear it */
+			val |= (chan->regs[AXIDMA_DMACR] & DMACR_RESET);
+
+			chan->regs[AXIDMA_DMACR] = val;
+
+			/* The reset bit triggers a reset for the whole engine */
+			if (val & DMACR_RESET)
+				axidma_reset(state);
+
+			axidma_ioc_update(chan);
+			axidma_dtimer_reset(chan, false);
+
+			/* R/S bit set and engine is not resetting, resume operation */
+			if ((val & DMACR_RS) && !(chan->regs[AXIDMA_DMACR] & DMACR_RESET)) {
+				chan->regs[AXIDMA_DMASR] &= ~(DMASR_HALTED);
+				chan->regs[AXIDMA_DMASR] &= ~(AXIDMA_DMASR_ERR_MASK);
+				/* halted -> paused */
+				chan->paused = true;
+			}
+
+			/* running -> paused */
+			if (!(val & DMACR_RS))
+				chan->paused = true;
+
+			break;
+		case AXIDMA_DMASR:
+			/* User can only write 1 to interrupt bits to disable them */
+			val &= ~(val & AXIDMA_DMASR_RW_MASK);
+			chan->regs[AXIDMA_DMASR] = val;
+			break;
+		case AXIDMA_CURDESC:
+		case AXIDMA_CURDESC_MSB:
+			/* If engine is running curdesc is RO */
+			if (chan->regs[AXIDMA_DMACR] & DMACR_RS)
+				break;
+			else
+				chan->regs[reg_offt] = val;
+			break;
+		case AXIDMA_TAILDESC_MSB:
+			chan->regs[reg_offt] = val;
+			/* If the channel is in paused state (waits for the first write
+			 * to taildesc) or IDLE (reached the taildesc), trigger processing. */
+			if ((chan->regs[AXIDMA_DMASR] & DMASR_IDLE) || chan->paused) {
+				if (chan->id == CHAN_MM2S)
+					axidma_mm2s_process(state);
+				else
+					qemu_flush_queued_packets(qemu_get_queue(state->nic));
+				chan->paused = false;
+			}
+			break;
+		/* Unused registers */
+		case AXIDMA_BUFFER_ADDR:
+		case AXIDMA_BUFFER_ADDR_MSB:
+		case AXIDMA_BUFFER_LENGTH:
+		case AXIDMA_SG_CTL:
+			break;
+		default:
+			chan->regs[reg_offt] = val;
+			break;
+	}
+
+	/* User may have updated irq enable/pending bits, re-evalutate intr status */
+	if ((reg_offt == AXIDMA_DMACR) || (reg_offt == AXIDMA_DMASR))
+		axidma_eval_intr_status(chan);
+}
+
+static const MemoryRegionOps axidma_ops = {
+	.read = axidma_read,
+	.write = axidma_write,
+	.endianness = DEVICE_NATIVE_ENDIAN,
+};
+
+/*****************\
+* INIT / REGISTER *
+\*****************/
+
+static void xxvnet_carv_realize(DeviceState *dev, Error **errp)
+{
+	struct axidma_state *state = XXVNET_CARV(dev);
+
+	address_space_init(&state->addr_space, get_system_memory(), "dma");
+
+	qemu_macaddr_default_if_unset(&state->conf.macaddr);
+	state->nic = qemu_new_nic(&net_xxvnet_carv_info, &state->conf,
+				 object_get_typename(OBJECT(dev)), dev->id,
+				 &dev->mem_reentrancy_guard, state);
+	qemu_format_nic_info_str(qemu_get_queue(state->nic), state->conf.macaddr.a);
+}
+
+static void xxvnet_carv_reset(DeviceState *dev)
+{
+	return;
+}
+
+static Property axidma_properties[] = {
+	DEFINE_PROP_UINT32("sg_clk_rate_hz", struct axidma_state, sg_clk_rate_hz, 50000000),
+	DEFINE_NIC_PROPERTIES(struct axidma_state, conf),
+ 	DEFINE_PROP_END_OF_LIST(),
+};
+
+static void xxvnet_carv_init(Object *obj)
+{
+	struct axidma_state *state = XXVNET_CARV(obj);
+
+	axidma_dtimer_init(state, &state->mm2s);
+	axidma_dtimer_init(state, &state->s2mm);
+	axidma_init_state(state);
+	memory_region_init_io(&state->iomem, obj, &axidma_ops, state,
+			      TYPE_XXVNET_CARV, (AXIDMA_CHAN_REG_MAX * 4) * 2);
+	sysbus_init_mmio(SYS_BUS_DEVICE(obj), &state->iomem);
+	sysbus_init_irq(SYS_BUS_DEVICE(obj), &state->mm2s.irq);
+	sysbus_init_irq(SYS_BUS_DEVICE(obj), &state->s2mm.irq);
+}
+
+static void xxvnet_carv_class_init(ObjectClass *klass, void *data)
+{
+    DeviceClass *dc = DEVICE_CLASS(klass);
+
+    dc->realize = xxvnet_carv_realize;
+    dc->reset = xxvnet_carv_reset;
+    device_class_set_props(dc, axidma_properties);
+}
+
+static const TypeInfo xxvnet_carv_info = {
+    .name          = TYPE_XXVNET_CARV,
+    .parent        = TYPE_SYS_BUS_DEVICE,
+    .instance_size = sizeof(struct axidma_state),
+    .instance_init = xxvnet_carv_init,
+    .class_init    = xxvnet_carv_class_init,
+};
+
+static void xxvnet_carv_register_types(void)
+{
+    type_register_static(&xxvnet_carv_info);
+}
+
+type_init(xxvnet_carv_register_types)
\ No newline at end of file
diff --git a/hw/riscv/Kconfig b/hw/riscv/Kconfig
index b6a5eb4..7a8caf0 100644
--- a/hw/riscv/Kconfig
+++ b/hw/riscv/Kconfig
@@ -46,6 +46,15 @@ config RISCV_VIRT
     select PLATFORM_BUS
     select ACPI
 
+config SDV3
+    bool
+    select PFLASH_CFI01
+    select SERIAL
+    select RISCV_ACLINT
+    select SIFIVE_PLIC
+    select XILINX_ETHLITE
+    select XXVNET_CARV
+
 config SHAKTI_C
     bool
     select RISCV_ACLINT
diff --git a/hw/riscv/meson.build b/hw/riscv/meson.build
index 2f7ee81..ce032bd 100644
--- a/hw/riscv/meson.build
+++ b/hw/riscv/meson.build
@@ -4,6 +4,7 @@ riscv_ss.add(when: 'CONFIG_RISCV_NUMA', if_true: files('numa.c'))
 riscv_ss.add(files('riscv_hart.c'))
 riscv_ss.add(when: 'CONFIG_OPENTITAN', if_true: files('opentitan.c'))
 riscv_ss.add(when: 'CONFIG_RISCV_VIRT', if_true: files('virt.c'))
+riscv_ss.add(when: 'CONFIG_SDV3', if_true: files('sdv3.c'))
 riscv_ss.add(when: 'CONFIG_SHAKTI_C', if_true: files('shakti_c.c'))
 riscv_ss.add(when: 'CONFIG_SIFIVE_E', if_true: files('sifive_e.c'))
 riscv_ss.add(when: 'CONFIG_SIFIVE_U', if_true: files('sifive_u.c'))
diff --git a/hw/riscv/sdv3.c b/hw/riscv/sdv3.c
new file mode 100644
index 0000000..5c41814
--- /dev/null
+++ b/hw/riscv/sdv3.c
@@ -0,0 +1,681 @@
+/*
+ * QEMU SDV3 board
+ *
+ * Copyright (c) 2023 ICS/FORTH.
+ */
+
+#include "qemu/osdep.h"
+#include "qemu/units.h"
+#include "qemu/error-report.h"
+#include "qemu/guest-random.h"
+#include "qapi/error.h"
+#include "hw/boards.h"
+#include "hw/loader.h"
+#include "hw/sysbus.h"
+#include "hw/qdev-properties.h"
+#include "hw/char/serial.h"
+#include "target/riscv/cpu.h"
+#include "hw/core/sysbus-fdt.h"
+#include "target/riscv/pmu.h"
+#include "hw/riscv/riscv_hart.h"
+#include "hw/riscv/boot.h"
+#include "hw/intc/riscv_aclint.h"
+#include "hw/intc/sifive_plic.h"
+#include "hw/misc/sifive_test.h"
+#include "hw/platform-bus.h"
+#include "chardev/char.h"
+#include "sysemu/device_tree.h"
+#include "sysemu/sysemu.h"
+#include "qapi/qapi-visit-common.h"
+#include "net/net.h"
+#include "hw/block/flash.h"
+
+/* SoC Properties */
+#define SDV3_CPUS_MAX			4
+#define	SDV3_TIMEBASE_FREQ		25000000
+#define SDV3_CLOCK_FREQ			50000000
+#define SDV3_PLIC_NUM_SOURCES		20
+#define SDV3_PLIC_NUM_PRIORITIES	7
+
+/* Memory/Device regions */
+enum {
+	SDV3_DEBUG,
+	SDV3_BROM,	/* Used by QEMU to place the reset vector (tiny bootrom) */
+	SDV3_TEST,	/* Doesn't exist in hw, used for reboot/halt */
+	SDV3_CLINT,
+	SDV3_PLIC,
+	SDV3_UART,
+	SDV3_EMACLITE,
+	SDV3_DMAETH,
+	SDV3_FLASH,	/* Doesn't exist in hw, we use it for testing bare metal apps on qemu */
+	SDV3_DRAM
+};
+
+/* IRQs */
+enum {
+	SDV3_UART_IRQ		= 1,
+	SDV3_EMACLITE_IRQ	= 2,
+	SDV3_DMAETH_TX_IRQ	= 3,
+	SDV3_DMAETH_RX_IRQ	= 4
+};
+
+/* Helper macros */
+#define TYPE_RISCV_SDV3_MACHINE MACHINE_TYPE_NAME("eupilot-vec")
+
+#define PFLASH_SECTOR_SIZE	(256 * KiB)
+#define PLIC_PRIORITY_BASE	0x00
+#define PLIC_PENDING_BASE	0x1000
+#define PLIC_ENABLE_BASE	0x2000
+#define PLIC_ENABLE_STRIDE	0x80
+#define PLIC_CONTEXT_BASE	0x200000
+#define PLIC_CONTEXT_STRIDE	0x1000
+#define PLIC_SIZE(__num_context) \
+    (PLIC_CONTEXT_BASE + (__num_context) * PLIC_CONTEXT_STRIDE)
+
+/* Machine state */
+struct Sdv3State {
+	/* Private (so that we can cast this to MachineState) */
+	MachineState parent;
+
+	/* Public */
+	Notifier machine_done;
+	RISCVHartArrayState cpus;
+	DeviceState *plic;
+	PFlashCFI01 *pflash;
+	int fdt_size;
+};
+
+typedef struct Sdv3State Sdv3State;
+
+#define SDV3_MACHINE(obj) \
+    OBJECT_CHECK(Sdv3State, (obj), TYPE_RISCV_SDV3_MACHINE)
+
+/* Memory map */
+static const MemMapEntry sdv3_memmap[] = {
+	[SDV3_DEBUG]	= { 0x0,		0x100 },
+	[SDV3_BROM]	= { 0x1000,		0x1000 },
+	[SDV3_TEST]	= { 0x100000,		0x1000 },
+	[SDV3_CLINT]	= { 0x2000000,		0x10000 },
+	[SDV3_PLIC]	= { 0xc000000,		PLIC_SIZE(SDV3_CPUS_MAX * 2) },
+	[SDV3_UART]	= { 0x40010000000,	0x1000 },
+	[SDV3_EMACLITE]	= { 0x40011000000,	0x3000 },
+	[SDV3_DMAETH]	= { 0x40011010000,	0x1000 },
+	[SDV3_FLASH]	= { 0x800000000000,	0x200000 },
+	[SDV3_DRAM]	= { 0x800000400000,	0x0 },
+};
+
+static void create_fdt_cpus(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	int hart_count = st->cpus.num_harts;
+	int i = 0;
+	char *cpu_name;
+	char *isa_string;
+	char *intc_name;
+
+	qemu_fdt_add_subnode(ms->fdt, "/cpus");
+	qemu_fdt_setprop_cell(ms->fdt, "/cpus", "timebase-frequency", SDV3_TIMEBASE_FREQ);
+	qemu_fdt_setprop_cell(ms->fdt, "/cpus", "#address-cells", 0x1);
+	qemu_fdt_setprop_cell(ms->fdt, "/cpus", "#size-cells", 0x0);
+
+	for (i = 0; i < hart_count; i++) {
+		RISCVCPU *cpu_ptr = &st->cpus.harts[i];
+
+		/* Populate /cpuX */
+		cpu_name = g_strdup_printf("/cpus/cpu@%d", st->cpus.hartid_base + i);
+		qemu_fdt_add_subnode(ms->fdt, cpu_name);
+		qemu_fdt_setprop_string(ms->fdt, cpu_name, "device_type", "cpu");
+		qemu_fdt_setprop_string(ms->fdt, cpu_name, "compatible", "riscv");
+		qemu_fdt_setprop_cell(ms->fdt, cpu_name, "reg", st->cpus.hartid_base + i);
+
+		isa_string = riscv_isa_string(cpu_ptr);
+		qemu_fdt_setprop_string(ms->fdt, cpu_name, "riscv,isa", isa_string);
+		g_free(isa_string);
+
+		qemu_fdt_setprop_string(ms->fdt, cpu_name, "mmu-type", "riscv,sv48");
+		qemu_fdt_setprop_string(ms->fdt, cpu_name, "status", "okay");
+
+		/* Populate it's local interrupt controller */
+		intc_name = g_strdup_printf("%s/interrupt-controller", cpu_name);
+		qemu_fdt_add_subnode(ms->fdt, intc_name);
+		qemu_fdt_setprop_cell(ms->fdt, intc_name, "#interrupt-cells", 1);
+		qemu_fdt_setprop(ms->fdt, intc_name, "interrupt-controller", NULL, 0);
+		qemu_fdt_setprop_string(ms->fdt, intc_name, "compatible", "riscv,cpu-intc");
+		qemu_fdt_setprop_cell(ms->fdt, intc_name, "phandle", i + 1);
+		g_free(intc_name);
+
+		g_free(cpu_name);
+	}
+}
+
+static void create_fdt_mem(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	char *mem_name;
+	uint64_t addr = sdv3_memmap[SDV3_DRAM].base;
+	uint64_t size = ms->ram_size;
+
+	mem_name = g_strdup_printf("/memory@%" PRIx64, addr);
+	qemu_fdt_add_subnode(ms->fdt, mem_name);
+	qemu_fdt_setprop_string(ms->fdt, mem_name, "device_type", "memory");
+	qemu_fdt_setprop_cells(ms->fdt, mem_name, "reg", addr >> 32, addr, size >> 32, size);
+	g_free(mem_name);
+}
+
+static void create_fdt_flash(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint64_t flash_addr = sdv3_memmap[SDV3_FLASH].base;
+	uint64_t flash_size = sdv3_memmap[SDV3_FLASH].size;
+	char *flash_name;
+
+	flash_name = g_strdup_printf("/flash@%" PRIx64, flash_addr);
+	qemu_fdt_add_subnode(ms->fdt, flash_name);
+	qemu_fdt_setprop_string(ms->fdt, flash_name, "compatible", "cfi-flash");
+	qemu_fdt_setprop_cells(ms->fdt, flash_name, "reg",
+				     flash_addr >> 32, flash_addr,
+				     flash_size >> 32, flash_size);
+	qemu_fdt_setprop_cell(ms->fdt, flash_name, "bank-width", 4);
+	g_free(flash_name);
+}
+
+static void create_fdt_pmu(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	char *pmu_name;
+	RISCVCPU hart = st->cpus.harts[0];
+
+	pmu_name = g_strdup_printf("/pmu");
+	qemu_fdt_add_subnode(ms->fdt, pmu_name);
+	qemu_fdt_setprop_string(ms->fdt, pmu_name, "compatible", "riscv,pmu");
+	riscv_pmu_generate_fdt_node(ms->fdt, hart.pmu_avail_ctrs, pmu_name);
+	g_free(pmu_name);
+}
+
+static void create_fdt_clint(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint64_t clint_addr = sdv3_memmap[SDV3_CLINT].base;
+	uint64_t clint_size = sdv3_memmap[SDV3_CLINT].size;
+	char *clint_name;
+	uint32_t *clint_cells;
+	int hart_count = st->cpus.num_harts;
+	int i = 0;
+
+	clint_name = g_strdup_printf("/soc/clint@%" PRIx64, clint_addr);
+	qemu_fdt_add_subnode(ms->fdt, clint_name);
+	qemu_fdt_setprop_string(ms->fdt, clint_name, "reg-names", "control");
+	qemu_fdt_setprop_string(ms->fdt, clint_name, "compatible", "riscv,clint0");
+	qemu_fdt_setprop_cells(ms->fdt, clint_name, "reg", clint_addr >> 32, clint_addr,
+			       clint_size >> 32, clint_size);
+
+	clint_cells = g_new0(uint32_t, hart_count * 4);
+	/* Note: cpuX/intc has phandle = X + 1, check out create_fdt_cpus() */
+	for (i = 0; i < hart_count; i++) {
+		clint_cells[i * 4 + 0] = cpu_to_be32(i + 1);
+		clint_cells[i * 4 + 1] = cpu_to_be32(IRQ_M_SOFT);
+		clint_cells[i * 4 + 2] = cpu_to_be32(i + 1);
+		clint_cells[i * 4 + 3] = cpu_to_be32(IRQ_M_TIMER);
+	}
+	qemu_fdt_setprop(ms->fdt, clint_name, "interrupts-extended", clint_cells,
+			 hart_count * sizeof(uint32_t) * 4);
+	g_free(clint_cells);
+	g_free(clint_name);
+}
+
+static void create_fdt_plic(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint64_t plic_addr = sdv3_memmap[SDV3_PLIC].base;
+	uint64_t plic_size = sdv3_memmap[SDV3_PLIC].size;
+	char *plic_name;
+	uint32_t *plic_cells;
+	int hart_count = st->cpus.num_harts;
+	/* Note: one phandle for each cpuX/intc and plic is afterwards */
+	uint32_t plic_phandle = hart_count + 1;
+	int i = 0;
+
+	plic_name = g_strdup_printf("/soc/plic@%" PRIx64, plic_addr);
+	qemu_fdt_add_subnode(ms->fdt, plic_name);
+	qemu_fdt_setprop_string(ms->fdt, plic_name, "compatible", "riscv,plic0");
+	qemu_fdt_setprop_cells(ms->fdt, plic_name, "reg", plic_addr >> 32, plic_addr,
+			       plic_size >> 32, plic_size);
+	qemu_fdt_setprop(ms->fdt, plic_name, "interrupt-controller", NULL, 0);
+	qemu_fdt_setprop_cell(ms->fdt, plic_name, "#interrupt-cells", 1);
+	qemu_fdt_setprop_cell(ms->fdt, plic_name, "#address-cells", 0);
+	plic_cells = g_new0(uint32_t, hart_count * 4);
+	/* Note: cpuX/intc has phandle = X + 1, check out create_fdt_cpus() */
+	for (i = 0; i < hart_count; i++) {
+		plic_cells[i * 4 + 0] = cpu_to_be32(i + 1);
+		plic_cells[i * 4 + 1] = cpu_to_be32(IRQ_M_EXT);
+		plic_cells[i * 4 + 2] = cpu_to_be32(i + 1);
+		plic_cells[i * 4 + 3] = cpu_to_be32(IRQ_S_EXT);
+        }
+        qemu_fdt_setprop(ms->fdt, plic_name, "interrupts-extended", plic_cells,
+			 hart_count * sizeof(uint32_t) * 4);
+	g_free(plic_cells);
+
+	qemu_fdt_setprop_cell(ms->fdt, plic_name, "riscv,ndev", SDV3_PLIC_NUM_SOURCES);
+	qemu_fdt_setprop_cell(ms->fdt, plic_name, "phandle", plic_phandle);
+
+	g_free(plic_name);
+}
+
+static void create_fdt_uart(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint64_t uart_addr = sdv3_memmap[SDV3_UART].base;
+	uint64_t uart_size = sdv3_memmap[SDV3_UART].size;
+	char *uart_name;
+	int hart_count = st->cpus.num_harts;
+	uint32_t plic_phandle = hart_count + 1;
+
+	uart_name = g_strdup_printf("/soc/uart@%" PRIx64, uart_addr);
+	qemu_fdt_add_subnode(ms->fdt, uart_name);
+	qemu_fdt_setprop_string(ms->fdt, uart_name, "compatible", "ns16550a");
+	qemu_fdt_setprop_cells(ms->fdt, uart_name, "reg", uart_addr >> 32, uart_addr,
+			       uart_size >> 32, uart_size);
+	qemu_fdt_setprop_cell(ms->fdt, uart_name, "clock-frequency", SDV3_CLOCK_FREQ);
+	qemu_fdt_setprop_cell(ms->fdt, uart_name, "current-speed", 115200);
+	qemu_fdt_setprop_cell(ms->fdt, uart_name, "reg-shift", 2);
+	qemu_fdt_setprop_cell(ms->fdt, uart_name, "interrupt-parent", plic_phandle);
+	qemu_fdt_setprop_cell(ms->fdt, uart_name, "interrupts", SDV3_UART_IRQ);
+
+	/* Add stdout-path on /chosen */
+	qemu_fdt_add_subnode(ms->fdt, "/chosen");
+	qemu_fdt_setprop_string(ms->fdt, "/chosen", "stdout-path", uart_name);
+
+	/* Create /aliases/serial0 */
+	qemu_fdt_add_subnode(ms->fdt, "/aliases");
+	qemu_fdt_setprop_string(ms->fdt, "/aliases", "serial0", uart_name);
+
+	g_free(uart_name);
+}
+
+static void create_fdt_emaclite(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint64_t emaclite_addr = sdv3_memmap[SDV3_EMACLITE].base;
+	uint64_t emaclite_size = sdv3_memmap[SDV3_EMACLITE].size;
+	char *emaclite_name;
+	char *emaclite_mdio_name;
+	int hart_count = st->cpus.num_harts;
+	uint32_t plic_phandle = hart_count + 1;
+
+	emaclite_name = g_strdup_printf("/soc/emaclite@%" PRIx64, emaclite_addr);
+	qemu_fdt_add_subnode(ms->fdt, emaclite_name);
+	qemu_fdt_setprop_string(ms->fdt, emaclite_name, "compatible", "xlnx,xps-ethernetlite-1.00.a");
+	qemu_fdt_setprop_cells(ms->fdt, emaclite_name, "reg", emaclite_addr >> 32, emaclite_addr,
+			       emaclite_size >> 32, emaclite_size);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "interrupt-parent", plic_phandle);
+	qemu_fdt_setprop_string(ms->fdt, emaclite_name, "interrupt-names", "ip2intc_irpt");
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "interrupts", SDV3_EMACLITE_IRQ);
+
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,duplex", 1);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,include-mdio", 0);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,include-global-buffers", 0);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,include-internal-loopback", 1);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,rx-ping-pong", 1);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,tx-ping-pong", 1);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,s-axi-id-width", 1);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,select-xpm", 1);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_name, "xlnx,use-internal", 0);
+
+	/* Create empty mdio subnode */
+	emaclite_mdio_name = g_strdup_printf("/soc/emaclite@%" PRIx64 "/mdio", emaclite_addr);
+	qemu_fdt_add_subnode(ms->fdt, emaclite_mdio_name);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_mdio_name, "#address-cells", 0x1);
+	qemu_fdt_setprop_cell(ms->fdt, emaclite_mdio_name, "#size-cells", 0x0);
+	g_free(emaclite_mdio_name);
+	
+	/* Create /aliases/ethernet0 */
+	qemu_fdt_setprop_string(ms->fdt, "/aliases", "ethernet0", emaclite_name);
+
+	g_free(emaclite_name);
+}
+
+static void create_fdt_ethdma(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint64_t xxvnet_addr = sdv3_memmap[SDV3_DMAETH].base;
+	uint64_t xxvnet_size = sdv3_memmap[SDV3_DMAETH].size;
+	static const char *interrupt_names[2] = {"mm2s_introut", "s2mm_introut"};
+	char *xxvnet_name;
+	int hart_count = st->cpus.num_harts;
+	uint32_t plic_phandle = hart_count + 1;
+	uint32_t ethdma_phandle = plic_phandle + 1;
+
+	xxvnet_name = g_strdup_printf("/soc/ethdma@%" PRIx64, xxvnet_addr);
+	qemu_fdt_add_subnode(ms->fdt, xxvnet_name);
+	qemu_fdt_setprop_string(ms->fdt, xxvnet_name, "compatible", "xlnx,xxv-ethernet-1.0-carv");
+	qemu_fdt_setprop_cells(ms->fdt, xxvnet_name, "reg", xxvnet_addr >> 32, xxvnet_addr,
+				xxvnet_size >> 32, xxvnet_size);
+	qemu_fdt_setprop_cell(ms->fdt, xxvnet_name, "interrupt-parent", plic_phandle);
+	qemu_fdt_setprop_string_array(ms->fdt, xxvnet_name, "interrupt-names",
+				      (char **)&interrupt_names, ARRAY_SIZE(interrupt_names));
+	qemu_fdt_setprop_cells(ms->fdt, xxvnet_name, "interrupts", SDV3_DMAETH_TX_IRQ, SDV3_DMAETH_RX_IRQ);
+
+	qemu_fdt_setprop_cell(ms->fdt, xxvnet_name, "xlnx,rxmem", 4096);
+	qemu_fdt_setprop_cell(ms->fdt, xxvnet_name, "carv,mtu", 1500);
+	qemu_fdt_setprop(ms->fdt, xxvnet_name, "xlnx,include-dre", NULL, 0);
+
+	/* TODO: Clean up this mess on the driver side ! */
+	qemu_fdt_setprop_cell(ms->fdt, xxvnet_name, "phandle", ethdma_phandle);
+	qemu_fdt_setprop_cell(ms->fdt, xxvnet_name, "axistream-connected", ethdma_phandle);
+
+	/* Create /aliases/ethernet0 */
+	qemu_fdt_setprop_string(ms->fdt, "/aliases", "ethernet1", xxvnet_name);
+
+	g_free(xxvnet_name);
+}
+
+static void create_fdt_test(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint64_t test_addr = sdv3_memmap[SDV3_TEST].base;
+	uint64_t test_size = sdv3_memmap[SDV3_TEST].size;
+	char *name;
+	int hart_count = st->cpus.num_harts;
+	uint32_t test_phandle = hart_count + 3;	/* PLIC's phandle + 2 */
+
+	name = g_strdup_printf("/soc/test@%" PRIx64, test_addr);
+	qemu_fdt_add_subnode(ms->fdt, name);
+	{
+		static const char *compat[3] = {
+			"sifive,test1", "sifive,test0", "syscon"
+		};
+		qemu_fdt_setprop_string_array(ms->fdt, name, "compatible",
+					(char **)&compat, ARRAY_SIZE(compat));
+	}
+	qemu_fdt_setprop_cells(ms->fdt, name, "reg", test_addr >> 32, test_addr,
+			       test_size >> 32, test_size);
+	qemu_fdt_setprop_cell(ms->fdt, name, "phandle", test_phandle);
+	g_free(name);
+
+	name = g_strdup_printf("/reboot");
+	qemu_fdt_add_subnode(ms->fdt, name);
+	qemu_fdt_setprop_string(ms->fdt, name, "compatible", "syscon-reboot");
+	qemu_fdt_setprop_cell(ms->fdt, name, "regmap", test_phandle);
+	qemu_fdt_setprop_cell(ms->fdt, name, "offset", 0x0);
+	qemu_fdt_setprop_cell(ms->fdt, name, "value", FINISHER_RESET);
+	g_free(name);
+
+	name = g_strdup_printf("/poweroff");
+	qemu_fdt_add_subnode(ms->fdt, name);
+	qemu_fdt_setprop_string(ms->fdt, name, "compatible", "syscon-poweroff");
+	qemu_fdt_setprop_cell(ms->fdt, name, "regmap", test_phandle);
+	qemu_fdt_setprop_cell(ms->fdt, name, "offset", 0x0);
+	qemu_fdt_setprop_cell(ms->fdt, name, "value", FINISHER_PASS);
+	g_free(name);
+}
+
+static void create_fdt(Sdv3State *st)
+{
+	MachineState *ms = MACHINE(st);
+	uint8_t rng_seed[32];
+
+	/* Initialize empty device tree */
+	ms->fdt = create_device_tree(&st->fdt_size);
+	if (!ms->fdt) {
+		error_report("create_device_tree() failed");
+		exit(1);
+	}
+
+	/* Create root node */
+	qemu_fdt_setprop_string(ms->fdt, "/", "model", "eupilot-qemu");
+	qemu_fdt_setprop_string(ms->fdt, "/", "compatible", "eupilot-vec");
+	qemu_fdt_setprop_cell(ms->fdt, "/", "#size-cells", 0x2);
+	qemu_fdt_setprop_cell(ms->fdt, "/", "#address-cells", 0x2);
+
+	/* Populate /cpus */
+	create_fdt_cpus(st);
+
+	/* Populate /memory */
+	create_fdt_mem(st);
+
+	/* Populate /flash */
+	create_fdt_flash(st);
+
+	/* Populate /pmu */
+	create_fdt_pmu(st);
+
+	/* Soc subnode/subtree */
+	qemu_fdt_add_subnode(ms->fdt, "/soc");
+	qemu_fdt_setprop(ms->fdt, "/soc", "ranges", NULL, 0);
+	qemu_fdt_setprop_string(ms->fdt, "/soc", "compatible", "simple-bus");
+	qemu_fdt_setprop_cell(ms->fdt, "/soc", "#size-cells", 0x2);
+	qemu_fdt_setprop_cell(ms->fdt, "/soc", "#address-cells", 0x2);
+
+	/* Populate /soc/clint */
+	create_fdt_clint(st);
+
+	/* Populate /soc/plic */
+	create_fdt_plic(st);
+
+	/* Populate /soc/uart, also creates /chosen/stdout-path and /aliases/serial0 */
+	create_fdt_uart(st);
+
+	/* Populate /soc/emaclite, also creates /aliases/ethernet0 */
+	create_fdt_emaclite(st);
+
+	/* Populate /soc/ethdma, also creates /aliases/ethernet1 */
+	create_fdt_ethdma(st);
+
+	/* Populate /soc/test, /reboot, /poweroff */
+	create_fdt_test(st);
+
+	/* Pass seed to RNG */
+	qemu_guest_getrandom_nofail(rng_seed, sizeof(rng_seed));
+	qemu_fdt_setprop(ms->fdt, "/chosen", "rng-seed", rng_seed, sizeof(rng_seed));
+}
+
+static void sdv3_machine_done(Notifier *notifier, void *data)
+{
+	Sdv3State *st = container_of(notifier, Sdv3State, machine_done);
+	MachineState *machine = MACHINE(st);
+	uint64_t fdt_load_addr = 0;
+	uint64_t start_addr = sdv3_memmap[SDV3_DRAM].base;
+	const char *firmware_name = riscv_default_firmware_name(&st->cpus);
+	uint64_t firmware_end_addr = 0;
+	uint64_t s_mode_payload_addr = 0;
+	uint64_t kernel_start_addr = 0;
+	BlockBackend *pflash_blk0;
+
+	/* Load firmware to DRAM: if -bios is provided we use that, instead we use the
+	 * built-in OpenSBI, if -bios none is passed then this will do nothing and will return start_addr. */
+	firmware_end_addr = riscv_find_and_load_firmware(machine, firmware_name, start_addr, NULL);
+
+	/* Check if user provided a payload in pflash */
+	pflash_blk0 = pflash_cfi01_get_blk(st->pflash);
+	if (pflash_blk0) {
+		/* We didn't get a firmware, run form pflash instead */
+		if(machine->firmware && !strcmp(machine->firmware, "none")) {
+			start_addr = sdv3_memmap[SDV3_FLASH].base;
+		/* We got a firmware, use it to run pflash as s-mode payload */
+		} else {
+			riscv_setup_firmware_boot(machine);
+			s_mode_payload_addr = sdv3_memmap[SDV3_FLASH].base;
+		}
+	}
+
+	/* Check if user provided a kernel (s-mode payload in elf format) */
+	if (machine->kernel_filename && !s_mode_payload_addr) {
+		kernel_start_addr = riscv_calc_kernel_start_addr(&st->cpus,
+                                                         firmware_end_addr);
+
+		s_mode_payload_addr = riscv_load_kernel(machine, &st->cpus, kernel_start_addr, true, NULL);
+	}
+
+	/* Put device tree in DRAM, note that riscv_load_fdt will pack fdt so we won't be able to modify it
+	 * afterwards, that's why this is the last thing we do before boot. */
+	fdt_load_addr = riscv_compute_fdt_addr(sdv3_memmap[SDV3_DRAM].base,
+                                           sdv3_memmap[SDV3_DRAM].size,
+                                           machine);
+	riscv_load_fdt(fdt_load_addr, machine->fdt);
+
+	/* load the reset vector to brom and ask it to jump to firmware/pflash and provide it with fdt/s-mode payload addr */
+	riscv_setup_rom_reset_vec(machine, &st->cpus, start_addr,
+				sdv3_memmap[SDV3_BROM].base, sdv3_memmap[SDV3_BROM].size,
+				s_mode_payload_addr, fdt_load_addr);
+
+}
+
+static void sdv3_machine_init(MachineState *machine)
+{
+	Sdv3State *st = SDV3_MACHINE(machine);
+	MemoryRegion *system_memory = get_system_memory();
+	MemoryRegion *mask_rom = g_new(MemoryRegion, 1);
+	NICInfo *nic0 = &nd_table[0];
+	NICInfo *nic1 = &nd_table[1];
+	DeviceState *dev;
+	int base_hartid = 0;
+	int hart_count = machine->smp.cpus;
+	char *plic_hart_config;
+	MemoryRegion *mr;
+
+	/* Register cpus */
+	object_initialize_child(OBJECT(machine), "cpus", &st->cpus,
+                                TYPE_RISCV_HART_ARRAY);
+        object_property_set_str(OBJECT(&st->cpus), "cpu-type",
+				machine->cpu_type, &error_abort);
+        object_property_set_int(OBJECT(&st->cpus), "hartid-base",
+				base_hartid, &error_abort);
+	object_property_set_int(OBJECT(&st->cpus), "num-harts",
+				hart_count, &error_abort);
+	sysbus_realize(SYS_BUS_DEVICE(&st->cpus), &error_fatal);
+
+	/* SiFive Test MMIO device (for reboot/halt) */
+	sifive_test_create(sdv3_memmap[SDV3_TEST].base);
+
+	/* Register CLINT */
+	riscv_aclint_swi_create(sdv3_memmap[SDV3_CLINT].base, base_hartid, hart_count, false);
+	riscv_aclint_mtimer_create(sdv3_memmap[SDV3_CLINT].base + RISCV_ACLINT_SWI_SIZE,
+				RISCV_ACLINT_DEFAULT_MTIMER_SIZE, base_hartid, hart_count,
+				RISCV_ACLINT_DEFAULT_MTIMECMP, RISCV_ACLINT_DEFAULT_MTIME,
+				SDV3_TIMEBASE_FREQ, true);
+
+	/* Register PLIC */
+	plic_hart_config = riscv_plic_hart_config_string(hart_count);
+	dev = sifive_plic_create(sdv3_memmap[SDV3_PLIC].base, plic_hart_config,
+				hart_count, base_hartid,
+				SDV3_PLIC_NUM_SOURCES, SDV3_PLIC_NUM_PRIORITIES,
+				PLIC_PRIORITY_BASE, PLIC_PENDING_BASE,
+				PLIC_ENABLE_BASE, PLIC_ENABLE_STRIDE,
+				PLIC_CONTEXT_BASE, PLIC_CONTEXT_STRIDE,
+				sdv3_memmap[SDV3_PLIC].size);
+	g_free(plic_hart_config);
+	st->plic = dev;
+
+	/* Register UART */
+	serial_mm_init(system_memory, sdv3_memmap[SDV3_UART].base, 2,
+			qdev_get_gpio_in(st->plic, SDV3_UART_IRQ), SDV3_CLOCK_FREQ,
+			serial_hd(0), DEVICE_LITTLE_ENDIAN);
+
+	/* Register emaclite */
+	qemu_check_nic_model(nic0, "xlnx.xps-ethernetlite");
+	dev = qdev_new("xlnx.xps-ethernetlite");
+	qdev_set_nic_properties(dev, nic0);
+	qdev_prop_set_uint32(dev, "tx-ping-pong", 1);
+	qdev_prop_set_uint32(dev, "rx-ping-pong", 1);
+	sysbus_realize_and_unref(SYS_BUS_DEVICE(dev), &error_fatal);
+	sysbus_connect_irq(SYS_BUS_DEVICE(dev), 0,
+			   qdev_get_gpio_in(st->plic, SDV3_EMACLITE_IRQ));	
+	mr = sysbus_mmio_get_region(SYS_BUS_DEVICE(dev), 0);
+	memory_region_add_subregion(system_memory, sdv3_memmap[SDV3_EMACLITE].base, mr);
+	error_report("emaclite at 0x%016lx\n", mr->addr);
+
+	/* Register ethdma */
+	qemu_check_nic_model(nic1, "xlnx.xxvnet_carv");
+	dev = qdev_new("xlnx.xxvnet_carv");
+	qdev_set_nic_properties(dev, nic1);
+	sysbus_realize_and_unref(SYS_BUS_DEVICE(dev), &error_fatal);
+	sysbus_connect_irq(SYS_BUS_DEVICE(dev), 0,
+			   qdev_get_gpio_in(st->plic, SDV3_DMAETH_TX_IRQ));
+	sysbus_connect_irq(SYS_BUS_DEVICE(dev), 1,
+			   qdev_get_gpio_in(st->plic, SDV3_DMAETH_RX_IRQ));
+	mr = sysbus_mmio_get_region(SYS_BUS_DEVICE(dev), 0);
+	memory_region_add_subregion(system_memory, sdv3_memmap[SDV3_DMAETH].base, mr);
+	error_report("dmaeth at 0x%016lx\n", mr->addr);
+
+	/* Register pflash */
+	pflash_cfi01_legacy_drive(st->pflash, drive_get(IF_PFLASH, 0, 0));
+	dev = DEVICE(st->pflash);
+	sysbus_realize_and_unref(SYS_BUS_DEVICE(dev), &error_fatal);
+    	memory_region_add_subregion(system_memory, sdv3_memmap[SDV3_FLASH].base,
+				    sysbus_mmio_get_region(SYS_BUS_DEVICE(dev), 0));
+
+	/* Register system memory */
+	memory_region_add_subregion(system_memory, sdv3_memmap[SDV3_DRAM].base, machine->ram);
+
+	/* Bootrom (QEMU's reset vector, see boot.c) */
+	memory_region_init_rom(mask_rom, NULL, "sdv3.brom", sdv3_memmap[SDV3_BROM].size, &error_fatal);
+	memory_region_add_subregion(system_memory, sdv3_memmap[SDV3_BROM].base, mask_rom);
+
+	/* load/create device tree */
+	if (machine->dtb) {
+		machine->fdt = load_device_tree(machine->dtb, &st->fdt_size);
+		if (!machine->fdt) {
+			error_report("load_device_tree() failed");
+			exit(1);
+		}
+	} else {
+		create_fdt(st);
+	}
+
+	st->machine_done.notify = sdv3_machine_done;
+	qemu_add_machine_init_done_notifier(&st->machine_done);
+}
+
+static void sdv3_machine_instance_init(Object *obj)
+{
+	Sdv3State *st = SDV3_MACHINE(obj);
+
+	/* Same as in virt.c */
+	DeviceState *dev = qdev_new(TYPE_PFLASH_CFI01);
+
+	qdev_prop_set_uint64(dev, "sector-length", PFLASH_SECTOR_SIZE);
+	qdev_prop_set_uint8(dev, "width", 4);
+	qdev_prop_set_uint8(dev, "device-width", 2);
+	qdev_prop_set_bit(dev, "big-endian", false);
+	qdev_prop_set_uint16(dev, "id0", 0x89);
+	qdev_prop_set_uint16(dev, "id1", 0x18);
+	qdev_prop_set_uint16(dev, "id2", 0x00);
+	qdev_prop_set_uint16(dev, "id3", 0x00);
+	qdev_prop_set_string(dev, "name", "sdv3.pflash");
+	qdev_prop_set_uint32(dev, "num-blocks", sdv3_memmap[SDV3_FLASH].size / PFLASH_SECTOR_SIZE);
+
+	object_property_add_child(OBJECT(st), "sdv3.pflash", OBJECT(dev));
+	object_property_add_alias(OBJECT(st), "pflash0", OBJECT(dev), "drive");
+
+	st->pflash = PFLASH_CFI01(dev);
+}
+
+static void sdv3_machine_class_init(ObjectClass *oc, void *data)
+{
+	MachineClass *mc = MACHINE_CLASS(oc);
+
+	mc->desc = "EUPILOT Prototype Simulator";
+	mc->init = sdv3_machine_init;
+	mc->default_cpu_type = TYPE_RISCV_CPU_EUPILOT;
+	mc->max_cpus = SDV3_CPUS_MAX;
+	mc->min_cpus = 1;
+	mc->default_cpus = mc->min_cpus;
+	mc->default_ram_id = "riscv.sdv3.ram";
+	mc->default_ram_size = 2 * GiB;
+}
+
+/* QEMU Glue */
+static const TypeInfo sdv3_machine_typeinfo = {
+    .name       = TYPE_RISCV_SDV3_MACHINE,
+    .parent     = TYPE_MACHINE,
+    .class_init = sdv3_machine_class_init,
+    .instance_init = sdv3_machine_instance_init,
+    .instance_size = sizeof(Sdv3State),
+};
+
+static void sdv3_machine_init_register_types(void)
+{
+    type_register_static(&sdv3_machine_typeinfo);
+}
+
+type_init(sdv3_machine_init_register_types)
diff --git a/target/riscv/cpu-qom.h b/target/riscv/cpu-qom.h
index 91b3361..1d97d95 100644
--- a/target/riscv/cpu-qom.h
+++ b/target/riscv/cpu-qom.h
@@ -42,6 +42,7 @@
 #define TYPE_RISCV_CPU_THEAD_C906       RISCV_CPU_TYPE_NAME("thead-c906")
 #define TYPE_RISCV_CPU_VEYRON_V1        RISCV_CPU_TYPE_NAME("veyron-v1")
 #define TYPE_RISCV_CPU_HOST             RISCV_CPU_TYPE_NAME("host")
+#define TYPE_RISCV_CPU_EUPILOT          RISCV_CPU_TYPE_NAME("eupilot")
 
 OBJECT_DECLARE_CPU_TYPE(RISCVCPU, RISCVCPUClass, RISCV_CPU)
 
diff --git a/target/riscv/cpu.c b/target/riscv/cpu.c
index 83c7c0c..c9931c3 100644
--- a/target/riscv/cpu.c
+++ b/target/riscv/cpu.c
@@ -535,6 +535,41 @@ static void rv64_veyron_v1_cpu_init(Object *obj)
 #endif
 }
 
+static void rv64_eupilot_cpu_init(Object *obj)
+{
+	RISCVCPU *cpu = RISCV_CPU(obj);
+	CPURISCVState *env = &cpu->env;
+	riscv_cpu_set_misa(env, MXL_RV64, RVI | RVM | RVA | RVF | RVD | RVC | RVU | RVS | RVV);
+
+#ifndef CONFIG_USER_ONLY
+	set_satp_mode_max_supported(RISCV_CPU(obj), VM_1_10_SV48);
+#endif
+
+	env->priv_ver = PRIV_VERSION_1_10_0;
+	env->vext_ver = VEXT_VERSION_1_00_0;
+
+	/* inherited from parent obj via riscv_cpu_init() */
+	cpu->cfg.ext_zifencei = true;
+	cpu->cfg.ext_zicsr = true;
+	cpu->cfg.mmu = true;
+
+	/* override defaults */
+	cpu->cfg.ext_zihintpause = false;
+	cpu->cfg.ext_zawrs = false;
+	cpu->cfg.ext_zfa = false;
+	cpu->cfg.pmp = false;
+	cpu->cfg.ext_sstc = false;
+	cpu->cfg.vlen = 128;
+	cpu->cfg.elen = 64;
+	cpu->cfg.ext_svadu = false;
+	cpu->cfg.ext_zba = false;
+	cpu->cfg.ext_zbb = false;
+	cpu->cfg.ext_zbc = false;
+	cpu->cfg.ext_zbs = false;
+	cpu->cfg.ext_zicbom = false;
+	cpu->cfg.ext_zicboz = false;
+}
+
 static void rv128_base_cpu_init(Object *obj)
 {
     if (qemu_tcg_mttcg_enabled()) {
@@ -1810,6 +1845,7 @@ static const TypeInfo riscv_cpu_type_infos[] = {
     DEFINE_CPU(TYPE_RISCV_CPU_SHAKTI_C,         rv64_sifive_u_cpu_init),
     DEFINE_CPU(TYPE_RISCV_CPU_THEAD_C906,       rv64_thead_c906_cpu_init),
     DEFINE_CPU(TYPE_RISCV_CPU_VEYRON_V1,        rv64_veyron_v1_cpu_init),
+    DEFINE_CPU(TYPE_RISCV_CPU_EUPILOT,          rv64_eupilot_cpu_init),
     DEFINE_DYNAMIC_CPU(TYPE_RISCV_CPU_BASE128,  rv128_base_cpu_init),
 #endif
 };
